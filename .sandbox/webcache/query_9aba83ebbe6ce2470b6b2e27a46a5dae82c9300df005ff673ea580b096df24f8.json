{"ts": 1756369750.1000357, "result": {"query": "github bradensui ollama-turbo-cli", "top_k": 5, "citations": [{"canonical_url": "https://github.com/ollama/ollama/releases/tag/v0.11.7", "archive_url": "", "title": "Release v0.11.7 · ollama/ollama", "date": null, "risk": "LOW", "risk_reasons": [], "browser_used": true, "kind": "html", "lines": [{"line": 42, "quote": "### Turbo via Ollama's CLI and libraries"}, {"line": 45, "quote": "[ollama.com/signup](https://ollama.com/signup) - Follow the"}, {"line": 3, "quote": "[DeepSeek-V3.1](https://ollama.com/library/deepseek-v3.1) is now available to run via Ollama."}, {"line": 7, "quote": "in Ollama's API:"}, {"line": 29, "quote": "## Turbo (in preview)"}, {"line": 31, "quote": "DeepSeek-V3.1 has over 671B parameters, and so a large amount of VRAM is required to run it. Ollama's [Turbo mode](https://ollama.com/turbo) (in preview) provides access to powerful hardware in the cloud you can use to run the model."}]}, {"canonical_url": "https://github.com/ollama/ollama", "archive_url": "", "title": "GitHub - ollama/ollama: Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models.", "date": null, "risk": "LOW", "risk_reasons": [], "browser_used": true, "kind": "html", "lines": [{"line": 98, "quote": "ollama create mario -f ./Modelfile"}, {"line": 99, "quote": "ollama run mario"}, {"line": 193, "quote": "[SwiftChat](https://github.com/aws-samples/swift-chat)(Cross-platform AI chat app supporting Apple Vision Pro via \"Designed for iPad\")[Enchanted](https://github.com/AugustDev/enchanted)"}, {"line": 195, "quote": "[pgai](https://github.com/timescale/pgai)- PostgreSQL as a vector database (Create and search embeddings from Ollama models using pgvector)[MindsDB](https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md)(Connects Ollama models with nearly 200 data platforms and apps)[chromem-go](https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go)with[example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama)[Kangaroo](https://github.com/dbkangaroo/kangaroo)(AI-powered SQL client and admin tool for popular databases)"}, {"line": 199, "quote": "[SwiftChat](https://github.com/aws-samples/swift-chat)(Lightning-fast Cross-platform AI chat app with native UI for Android, iOS, and iPad)[Enchanted](https://github.com/AugustDev/enchanted)[Maid](https://github.com/Mobile-Artificial-Intelligence/maid)[Ollama App](https://github.com/JHubi1/ollama-app)(Modern and easy-to-use multi-platform client for Ollama)[ConfiChat](https://github.com/1runeberg/confichat)(Lightweight, standalone, multi-platform, and privacy-focused LLM chat interface with optional encryption)[Ollama Android Chat](https://github.com/sunshine0523/OllamaServer)(No need for Termux, start the Ollama service with one click on an Android device)[Reins](https://github.com/ibrahimcetin/reins)(Easily tweak parameters, customize system prompts per chat, and enhance your AI experiments with reasoning model support.)"}, {"line": 201, "quote": "[Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama)[Discollama](https://github.com/mxyng/discollama)(Discord bot inside the Ollama discord channel)[Continue](https://github.com/continuedev/continue)[Vibe](https://github.com/thewh1teagle/vibe)(Transcribe and analyze meetings with Ollama)[Obsidian Ollama plugin](https://github.com/hinterdupfinger/obsidian-ollama)[Logseq Ollama plugin](https://github.com/omagdy7/ollama-logseq)[NotesOllama](https://github.com/andersrex/notesollama)(Apple Notes Ollama plugin)[Dagger Chatbot](https://github.com/samalba/dagger-chatbot)[Discord AI Bot](https://github.com/mekb-turtle/discord-ai-bot)[Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram)[Hass Ollama Conversation](https://github.com/ej52/hass-ollama-conversation)[Rivet plugin](https://github.com/abrenneke/rivet-plugin-ollama)[Obsidian BMO Chatbot plugin](https://github.com/longy2k/obsidian-bmo-chatbot)[Cliobot](https://github.com/herval/cliobot)(Telegram bot with Ollama support)[Copilot for Obsidian plugin](https://github.com/logancyang/obsidian-copilot)[Obsidian Local GPT plugin](https://github.com/pfrankov/obsidian-local-gpt)[Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama)[Llama Coder](https://github.com/ex3ndr/llama-coder)(Copilot alternative using Ollama)[Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot)(Proxy that allows you to use Ollama as a copilot like GitHub Copilot)[twinny](https://github.com/rjmacarthy/twinny)(Copilot and Copilot chat alternative using Ollama)[Wingman-AI](https://github.com/RussellCanfield/wingman-ai)(Copilot code and chat alternative using Ollama and Hugging Face)[Page Assist](https://github.com/n4ze3m/page-assist)(Chrome Extension)[Plasmoid Ollama Control](https://github.com/imoize/plasmoid-ollamacontrol)(KDE Plasma extension that allows you to quickly manage/control Ollama model)[AI Telegram Bot](https://github.com/tusharhero/aitelegrambot)(Telegram bot using Ollama in backend)[AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text)(Sublime Text 4 AI assistant plugin with Ollama support)[Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama)(Generalized TypeScript Discord Bot w/ Tuning Documentation)[ChatGPTBox: All in one browser extension](https://github.com/josStorer/chatGPTBox)with[Integrating Tutorial](https://github.com/josStorer/chatGPTBox/issues/616#issuecomment-1975186467)[Discord AI chat/moderation bot](https://github.com/rapmd73/Companion)Chat/moderation bot written in python. Uses Ollama to create personalities.[Headless Ollama](https://github.com/nischalj10/headless-ollama)(Scripts to automatically install ollama client & models on any OS for apps that depend on ollama server)[Terraform AWS Ollama & Open WebUI](https://github.com/xuyangbocn/terraform-aws-self-host-llm)(A Terraform module to deploy on AWS a ready-to-use Ollama service, together with its front-end Open WebUI service.)[node-red-contrib-ollama](https://github.com/jakubburkiewicz/node-red-contrib-ollama)[Local AI Helper](https://github.com/ivostoykov/localAI)(Chrome and Firefox extensions that enable interactions with the active tab and customisable API endpoints. Includes secure storage for user prompts.)[vnc-lm](https://github.com/jake83741/vnc-lm)(Discord bot for messaging with LLMs through Ollama and LiteLLM. Seamlessly move between local and flagship models.)[LSP-AI](https://github.com/SilasMarvin/lsp-ai)(Open-source language server for AI-powered functionality)[QodeAssist](https://github.com/Palm1r/QodeAssist)(AI-powered coding assistant plugin for Qt Creator)[Obsidian Quiz Generator plugin](https://github.com/ECuiDev/obsidian-quiz-generator)[AI Summmary Helper plugin](https://github.com/philffm/ai-summary-helper)[TextCraft](https://github.com/suncloudsmoon/TextCraft)(Copilot in Word alternative using Ollama)[Alfred Ollama](https://github.com/zeitlings/alfred-ollama)(Alfred Workflow)[TextLLaMA](https://github.com/adarshM84/TextLLaMA)A Chrome Extension that helps you write emails, correct grammar, and translate into any language[Simple-Discord-AI](https://github.com/zyphixor/simple-discord-ai)[LLM Telegram Bot](https://github.com/innightwolfsleep/llm_telegram_bot)(telegram bot, primary for RP. Oobabooga-like buttons,[A1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui)API integration e.t.c)[mcp-llm](https://github.com/sammcj/mcp-llm)(MCP Server to allow LLMs to call other LLMs)[SimpleOllamaUnity](https://github.com/HardCodeDev777/SimpleOllamaUnity)(Unity Engine extension for communicating with Ollama in a few lines of code. Also works at runtime)[UnityCodeLama](https://github.com/HardCodeDev777/UnityCodeLama)(Unity Edtior tool to analyze scripts via Ollama)[NativeMind](https://github.com/NativeMindBrowser/NativeMindExtension)(Private, on-device AI Assistant, no cloud dependencies)[GMAI - Gradle Managed AI](https://gmai.premex.se/)(Gradle plugin for automated Ollama lifecycle management during build phases)"}]}, {"canonical_url": "https://github.com/open-webui/open-webui", "archive_url": "", "title": "GitHub - open-webui/open-webui: User-friendly AI Interface (Supports Ollama, OpenAI API, ...)", "date": null, "risk": "LOW", "risk_reasons": [], "browser_used": true, "kind": "html", "lines": [{"line": 139, "quote": "If you wish to utilize Open WebUI with Ollama included or CUDA acceleration, we recommend utilizing our official images tagged with either `:cuda`"}, {"line": 141, "quote": "or `:ollama`"}, {"line": 3, "quote": "**Ollama**and"}, {"line": 25, "quote": "**Effortless Setup**: Install seamlessly using Docker or Kubernetes (kubectl, kustomize or helm) for a hassle-free experience with support for both`:ollama`"}, {"line": 98, "quote": "**Role-Based Access Control (RBAC)**: Ensure secure access with restricted permissions; only authorized individuals can access your Ollama, and exclusive model creation/pulling rights are reserved for administrators. -"}, {"line": 104, "quote": "**Pipelines, Open WebUI Plugin Support**: Seamlessly integrate custom logic and Python libraries into Open WebUI using[Pipelines Plugin Framework](https://github.com/open-webui/pipelines). Launch your Pipelines instance, set the OpenAI URL to the Pipelines URL, and explore endless possibilities.[Examples](https://github.com/open-webui/pipelines/tree/main/examples)include**Function Calling**, User**Rate Limiting**to control access,**Usage Monitoring**with tools like Langfuse,**Live Translation with LibreTranslate**for multilingual support,**Toxic Message Filtering**and much more. -"}]}, {"canonical_url": "https://github.com/ollama/ollama/blob/main/docs/turbo.md", "archive_url": "", "title": "ollama/docs/turbo.md at main · ollama/ollama", "date": null, "risk": "LOW", "risk_reasons": [], "browser_used": true, "kind": "html", "lines": []}, {"canonical_url": "https://github.com/RooCodeInc/Roo-Code/issues/7147", "archive_url": "", "title": "Support Ollama Turbo · Issue #7147 · RooCodeInc/Roo-Code", "date": "2025-08-16T21:59:35", "risk": "LOW", "risk_reasons": [], "browser_used": true, "kind": "html", "lines": [{"line": 37, "quote": "Implement support for **Ollama Turbo** mode within the Roo Code Ollama integration. This enables users to utilize Turbo’s datacenter-grade hardware execution from Roo Code, CLI, and API, following the [Ollama Turbo documentation](https://github.com/ollama/ollama/blob/main/docs/turbo.md)."}, {"line": 39, "quote": "There is already the base URL field that can be customized to [https://ollama.com](https://ollama.com), you just miss a field `Ollama API Key`"}, {"line": 3, "quote": "[cline/cline](/cline/cline)-"}, {"line": 11, "quote": "[Issue - In ProgressSomeone is actively working on this. Should link to a PR soon.](https://github.com/RooCodeInc/Roo-Code/issues?q=state%3Aopen%20label%3A%22Issue%20-%20In%20Progress%22)Someone is actively working on this. Should link to a PR soon."}, {"line": 55, "quote": "Expect a field to configure Ollama API key sent as bearer in the headers for Ollama Turbo support."}]}], "policy": {"respect_robots": true, "allow_browser": true, "cache_ttl_seconds": 86400}}}