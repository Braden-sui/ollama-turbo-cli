<!DOCTYPE html><html lang="en"><head><link rel="stylesheet" href="/_next/static/css/00bc42cc0fffc127.css" data-precedence="next"><script type="text/javascript" async="" src="https://s3-us-west-2.amazonaws.com/b2bjsstore/b/W6Z57HQ7J8OX/W6Z57HQ7J8OX.js.gz"></script><script async="" src="https://www.googletagmanager.com/gtm.js?id=GTM-KLW63SD9"></script><script src="/_next/static/chunks/fd9d1056-47aa93076cc391d3.js" async=""></script><script src="/_next/static/chunks/2117-37c0d88e11a7cb0e.js" async=""></script><script src="/_next/static/chunks/main-app-522444e270596d81.js" async=""></script><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebAPI","name":"Exa API","description":"AI search engine with website crawler, search API, SERP API, and deep research API. Built for querying, crawling, and extracting structured web data.","applicationCategory":"Search API","keywords":["ai search engine","serp api","best ai search engine","search api","deep research api","web search api","web search ai","ai search api","deepresearch api","web crawling api","website crawler"],"operatingSystem":"All","url":"https://exa.ai","provider":{"@type":"Organization","name":"Exa Labs","url":"https://exa.ai"},"offers":{"@type":"Offer","price":"0.00","priceCurrency":"USD"}}</script><script>(self.__next_s=self.__next_s||[]).push([0,{"children":"(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\n            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\n            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n            })(window,document,'script','dataLayer','GTM-KLW63SD9');","id":"gtm-script"}])</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" nomodule=""></script><style data-styled="active" data-styled-version="6.1.12"></style><script id="gtm-script">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
            })(window,document,'script','dataLayer','GTM-KLW63SD9');</script><meta name="viewport" content="width=device-width, initial-scale=1"><meta charset="utf-8"><title>Our AI Research: How We Evaluate Semantic Search Technology</title><meta name="description" content="Get an inside look at the rigorous evaluation process at Exa. Our AI research blog shows how we ensure our neural network search engine provides the highest quality results."><meta name="application-name" content="Exa"><link rel="author" href="https://exa.ai"><meta name="author" content="Exa Labs"><meta name="keywords" content="metaphor,exa,api,search,ai,llms"><meta property="og:title" content="Our AI Research: How We Evaluate Semantic Search Technology"><meta property="og:description" content="Get an inside look at the rigorous evaluation process at Exa. Our AI research blog shows how we ensure our neural network search engine provides the highest quality results."><meta property="og:image" content="https://exa.imgix.net/search_quality_graphs_smaller.png"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@exaailabs"><meta name="twitter:creator" content="@exaailabs"><meta name="twitter:title" content="Exa"><meta name="twitter:description" content="The Exa API retrieves the best, realtime data from the web for your AI"><meta name="twitter:image" content="https://exa.imgix.net/og-image.png/"><link rel="icon" href="/images/favicon-32x32.png"><meta name="keywords" content="ai search engine, web search api, webcrawler, serp api, web api, google search api, google serp api, people search engines, perplexity ai search engine features, ai search engine free, search engine ai, free people search engines, best ai search engine, web api security, ai search engines, search api, free ai search engine, web scraping api, bing search api, webcrawler search engine, search engine rankings api"><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebAPI","name":"Exa API","description":"AI search engine with website crawler, search API, SERP API, and deep research API. Built for querying, crawling, and extracting structured web data.","applicationCategory":"Search API","keywords":["ai search engine","serp api","best ai search engine","search api","deep research api","web search api","web search ai","ai search api","deepresearch api","web crawling api","website crawler"],"operatingSystem":"All","url":"https://exa.ai","provider":{"@type":"Organization","name":"Exa Labs","url":"https://exa.ai"},"offers":{"@type":"Offer","price":"0.00","priceCurrency":"USD"}}</script><script>(self.__next_s=self.__next_s||[]).push([0,{"children":"(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\n            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\n            j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n            })(window,document,'script','dataLayer','GTM-KLW63SD9');","id":"gtm-script"}])</script><style data-emotion="css-global" data-s="">@-webkit-keyframes slideOut{0%{-webkit-transform:translateY(-50%) translateX(0);-moz-transform:translateY(-50%) translateX(0);-ms-transform:translateY(-50%) translateX(0);transform:translateY(-50%) translateX(0);opacity:1;}100%{-webkit-transform:translateY(-50%) translateX(15px);-moz-transform:translateY(-50%) translateX(15px);-ms-transform:translateY(-50%) translateX(15px);transform:translateY(-50%) translateX(15px);opacity:0;}}@keyframes slideOut{0%{-webkit-transform:translateY(-50%) translateX(0);-moz-transform:translateY(-50%) translateX(0);-ms-transform:translateY(-50%) translateX(0);transform:translateY(-50%) translateX(0);opacity:1;}100%{-webkit-transform:translateY(-50%) translateX(15px);-moz-transform:translateY(-50%) translateX(15px);-ms-transform:translateY(-50%) translateX(15px);transform:translateY(-50%) translateX(15px);opacity:0;}}@-webkit-keyframes slideIn{0%{-webkit-transform:translateY(-50%) translateX(-8px);-moz-transform:translateY(-50%) translateX(-8px);-ms-transform:translateY(-50%) translateX(-8px);transform:translateY(-50%) translateX(-8px);opacity:0;}100%{-webkit-transform:translateY(-50%) translateX(0);-moz-transform:translateY(-50%) translateX(0);-ms-transform:translateY(-50%) translateX(0);transform:translateY(-50%) translateX(0);opacity:1;}}@keyframes slideIn{0%{-webkit-transform:translateY(-50%) translateX(-8px);-moz-transform:translateY(-50%) translateX(-8px);-ms-transform:translateY(-50%) translateX(-8px);transform:translateY(-50%) translateX(-8px);opacity:0;}100%{-webkit-transform:translateY(-50%) translateX(0);-moz-transform:translateY(-50%) translateX(0);-ms-transform:translateY(-50%) translateX(0);transform:translateY(-50%) translateX(0);opacity:1;}}.arrow-slide-out{position:absolute;top:50%;left:0;-webkit-transform:translateY(-50%) translateX(0);-moz-transform:translateY(-50%) translateX(0);-ms-transform:translateY(-50%) translateX(0);transform:translateY(-50%) translateX(0);opacity:1;}.arrow-slide-in{position:absolute;top:50%;left:0;-webkit-transform:translateY(-50%) translateX(-8px);-moz-transform:translateY(-50%) translateX(-8px);-ms-transform:translateY(-50%) translateX(-8px);transform:translateY(-50%) translateX(-8px);opacity:0;}.group-hover-link:not(:disabled):hover .arrow-slide-out{-webkit-animation:slideOut 0.2s forwards;animation:slideOut 0.2s forwards;}.group-hover-link:not(:disabled):hover .arrow-slide-in{-webkit-animation:slideIn 0.2s forwards;animation:slideIn 0.2s forwards;-webkit-animation-delay:0.2s;animation-delay:0.2s;}.group-hover-link:not(:hover) .arrow-slide-out,.group-hover-link:disabled .arrow-slide-out{-webkit-animation:none;animation:none;}.group-hover-link:not(:hover) .arrow-slide-in,.group-hover-link:disabled .arrow-slide-in{-webkit-animation:none;animation:none;-webkit-animation-delay:0s;animation-delay:0s;}</style><script src="https://cdn.jsdelivr.net/npm/psl/dist/psl.min.js"></script></head><body style="margin-top: var(--nav-height); background: var(--black); display: flex; flex-direction: column; color: var(--white); min-height: 100vh; width: 100%;"><script type="text/javascript" crossorigin="anonymous" src="/ingest/static/recorder.js?v=1.209.1"></script><script type="text/javascript" crossorigin="anonymous" src="/ingest/array/phc_ebUSDbDOBtuw7SuEOBFtu315tugMMml4W8zoT4DNMC4/config.js"></script><script src="/_next/static/chunks/webpack-1de96c7e6b616b98.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/00bc42cc0fffc127.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[12846,[],\"\"]\n4:I[19107,[],\"ClientPageRoot\"]\n5:I[39372,[\"203\",\"static/chunks/203-d86cdf1b010a1897.js\",\"1942\",\"static/chunks/1942-78f5ab3b6fb6b984.js\",\"881\",\"static/chunks/881-75cc7ca0941f30a3.js\",\"2207\",\"static/chunks/2207-46f255d205cc7108.js\",\"8172\",\"static/chunks/8172-c3f1afdb7fca88a9.js\",\"8701\",\"static/chunks/app/blog/evals-at-exa/page-690e0b8a5ddbea9f.js\"],\"default\",1]\n6:I[4707,[],\"\"]\n7:I[36423,[],\"\"]\n8:I[88003,[\"7909\",\"static/chunks/cd24890f-b6476379b3721838.js\",\"203\",\"static/chunks/203-d86cdf1b010a1897.js\",\"6593\",\"static/chunks/6593-010f07c8981fc226.js\",\"9491\",\"static/chunks/9491-b855134784016114.js\",\"5745\",\"static/chunks/5745-161377f749f95ac0.js\",\"9942\",\"static/chunks/9942-4b545ece02b85780.js\",\"881\",\"static/chunks/881-75cc7ca0941f30a3.js\",\"3185\",\"static/chunks/app/layout-ae8694fa08b5e9f9.js\"],\"\"]\n9:I[56676,[\"7909\",\"static/chunks/cd24890f-b6476379b3721838.js\",\"203\",\"static/chunks/203-d86cdf1b010a1897.js\",\"6593\",\"static/chunks/6593-010f07c8981fc226.js\",\"9491\",\"static/chunks/9491-b855134784016114.js\",\"5745\",\"static/chunks/5745-161377f749f95ac0.js\",\"9942\",\"static/chunks/9942-4b545ece02b85780.js\",\"881\",\"static/chunks/881-75cc7ca0941f30a3.js\",\"3185\",\"static/chunks/app/layout-ae8694fa08b5e9f9.js\"],\"PHProvider\"]\na:I[97906,[\"7909\",\"static/chunks/cd24890f-b6476379b3721838.js\",\"203\",\"static/chunks/203-d86cdf1b010a1897.js\",\"6593\",\"static/chunks/6593-010f07c8981fc226.js\",\"9491\",\"static/chunks/9491-b855134784016114.js\",\"5745\",\"static/chunks/5745-161377f749f95ac0.js\",\"9942\",\"static/chunks/9942-4b545ece02b85780.js\",\"881\",\"static/chunks/881-75cc7ca0941f30a3.js\",\"3185\",\"static/chunks/app/layout-ae8694fa08b5e9f9.js\"],\"default\"]\nb:I[54100,[\"7909\",\"static/chunks/cd24890f-b6476379b3721838.js\",\"203\",\"static/chunks/203-d86cdf1b010a1897.js\",\"6593\",\"static/chunks/6593-010f07c8981fc226.js\",\"9491\",\"static/chunks/9491-b855134784016114.js\",\"5745\",\"static/chunks/5745-161377f749f95ac0.js\",\"9942\",\"static/chunks/9942-4b545ece02b85780.js\",\"881\",\"static/chunks/881-75cc7ca0941f30a3.js\",\"3185\",\"static/chunks/app/layout-ae8694fa08b5e9f9.js\"]"])</script><script>self.__next_f.push([1,",\"default\"]\nc:I[75292,[\"203\",\"static/chunks/203-d86cdf1b010a1897.js\",\"9160\",\"static/chunks/app/not-found-eb45d62675716edb.js\"],\"default\"]\nd:\"$Sreact.suspense\"\ne:I[81523,[\"7909\",\"static/chunks/cd24890f-b6476379b3721838.js\",\"203\",\"static/chunks/203-d86cdf1b010a1897.js\",\"6593\",\"static/chunks/6593-010f07c8981fc226.js\",\"9491\",\"static/chunks/9491-b855134784016114.js\",\"5745\",\"static/chunks/5745-161377f749f95ac0.js\",\"9942\",\"static/chunks/9942-4b545ece02b85780.js\",\"881\",\"static/chunks/881-75cc7ca0941f30a3.js\",\"3185\",\"static/chunks/app/layout-ae8694fa08b5e9f9.js\"],\"BailoutToCSR\"]\nf:I[16442,[\"7909\",\"static/chunks/cd24890f-b6476379b3721838.js\",\"203\",\"static/chunks/203-d86cdf1b010a1897.js\",\"6593\",\"static/chunks/6593-010f07c8981fc226.js\",\"9491\",\"static/chunks/9491-b855134784016114.js\",\"5745\",\"static/chunks/5745-161377f749f95ac0.js\",\"9942\",\"static/chunks/9942-4b545ece02b85780.js\",\"881\",\"static/chunks/881-75cc7ca0941f30a3.js\",\"3185\",\"static/chunks/app/layout-ae8694fa08b5e9f9.js\"],\"default\"]\n11:I[61060,[],\"\"]\n12:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L2\",null,{\"buildId\":\"Zl8Z8ipT5M2vhw6P8wyv9\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"blog\",\"evals-at-exa\"],\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[\"evals-at-exa\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"blog\",{\"children\":[\"evals-at-exa\",{\"children\":[\"__PAGE__\",{},[[\"$L3\",[\"$\",\"$L4\",null,{\"props\":{\"params\":{},\"searchParams\":{}},\"Component\":\"$5\"}],null],null],null]},[[null,[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",\"evals-at-exa\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null],null]},[[null,[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/00bc42cc0fffc127.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"keywords\",\"content\":\"ai search engine, web search api, webcrawler, serp api, web api, google search api, google serp api, people search engines, perplexity ai search engine features, ai search engine free, search engine ai, free people search engines, best ai search engine, web api security, ai search engines, search api, free ai search engine, web scraping api, bing search api, webcrawler search engine, search engine rankings api\"}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebAPI\\\",\\\"name\\\":\\\"Exa API\\\",\\\"description\\\":\\\"AI search engine with website crawler, search API, SERP API, and deep research API. Built for querying, crawling, and extracting structured web data.\\\",\\\"applicationCategory\\\":\\\"Search API\\\",\\\"keywords\\\":[\\\"ai search engine\\\",\\\"serp api\\\",\\\"best ai search engine\\\",\\\"search api\\\",\\\"deep research api\\\",\\\"web search api\\\",\\\"web search ai\\\",\\\"ai search api\\\",\\\"deepresearch api\\\",\\\"web crawling api\\\",\\\"website crawler\\\"],\\\"operatingSystem\\\":\\\"All\\\",\\\"url\\\":\\\"https://exa.ai\\\",\\\"provider\\\":{\\\"@type\\\":\\\"Organization\\\",\\\"name\\\":\\\"Exa Labs\\\",\\\"url\\\":\\\"https://exa.ai\\\"},\\\"offers\\\":{\\\"@type\\\":\\\"Offer\\\",\\\"price\\\":\\\"0.00\\\",\\\"priceCurrency\\\":\\\"USD\\\"}}\"}}],[\"$\",\"$L8\",null,{\"id\":\"gtm-script\",\"strategy\":\"beforeInteractive\",\"dangerouslySetInnerHTML\":{\"__html\":\"(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\\n            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\\n            j=d.createElement(s),dl=l!='dataLayer'?'\u0026l='+l:'';j.async=true;j.src=\\n            'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\\n            })(window,document,'script','dataLayer','GTM-KLW63SD9');\"}}],[\"$\",\"$L8\",null,{\"async\":true,\"src\":\"https://cdn.tolt.io/tolt.js\",\"data-tolt\":\"pk_Zaf65kQFEMtUeofUeGdum5pK\",\"strategy\":\"afterInteractive\"}]]}],[\"$\",\"$L9\",null,{\"children\":[\"$\",\"body\",null,{\"style\":{\"marginTop\":\"var(--nav-height)\",\"background\":\"var(--black)\",\"display\":\"flex\",\"flexDirection\":\"column\",\"color\":\"var(--white)\",\"minHeight\":\"100vh\",\"width\":\"100%\"},\"children\":[[\"$\",\"noscript\",null,{\"children\":\"Exa is a modern AI search engine with SERP API, website crawler tools, and deep research API. Power your app with web search AI and web crawling API.\"}],[\"$\",\"noscript\",null,{\"children\":[\"$\",\"iframe\",null,{\"src\":\"https://www.googletagmanager.com/ns.html?id=GTM-KLW63SD9\",\"height\":\"0\",\"width\":\"0\",\"style\":{\"display\":\"none\",\"visibility\":\"hidden\"}}]}],[\"$\",\"$La\",null,{\"children\":[\"$\",\"$Lb\",null,{\"children\":[\"$\",\"$L6\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L7\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"$Lc\",null,{}],\"notFoundStyles\":[]}]}]}],[\"$\",\"$d\",null,{\"fallback\":null,\"children\":[\"$\",\"$Le\",null,{\"reason\":\"next/dynamic\",\"children\":[\"$\",\"$Lf\",null,{}]}]}]]}]}]]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L10\"],\"globalErrorComponent\":\"$11\",\"missingSlots\":\"$W12\"}]\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Our AI Research: How We Evaluate Semantic Search Technology\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Get an inside look at the rigorous evaluation process at Exa. Our AI research blog shows how we ensure our neural network search engine provides the highest quality results.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"application-name\",\"content\":\"Exa\"}],[\"$\",\"link\",\"5\",{\"rel\":\"author\",\"href\":\"https://exa.ai\"}],[\"$\",\"meta\",\"6\",{\"name\":\"author\",\"content\":\"Exa Labs\"}],[\"$\",\"meta\",\"7\",{\"name\":\"keywords\",\"content\":\"metaphor,exa,api,search,ai,llms\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:title\",\"content\":\"Our AI Research: How We Evaluate Semantic Search Technology\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:description\",\"content\":\"Get an inside look at the rigorous evaluation process at Exa. Our AI research blog shows how we ensure our neural network search engine provides the highest quality results.\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image\",\"content\":\"https://exa.imgix.net/search_quality_graphs_smaller.png\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:site\",\"content\":\"@exaailabs\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:creator\",\"content\":\"@exaailabs\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"Exa\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"The Exa API retrieves the best, realtime data from the web for your AI\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://exa.imgix.net/og-image.png/\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/images/favicon-32x32.png\"}]]\n3:null\n"])</script><noscript>Exa is a modern AI search engine with SERP API, website crawler tools, and deep research API. Power your app with web search AI and web crawling API.</noscript><noscript></noscript><div id="navbar" style="top: -60px;"><nav class="w-full max-h-[var(--nav-height)] h-[var(--nav-height)] fixed top-0 z-[100] bg-white transition-all duration-200 border-b border-gray-200"><div class="p-0 h-full bg-white py-2.5"><div class="max-w-7xl mx-auto pl-2 pr-0 flex justify-between h-full items-center"><a href="/" class="relative text-2xl text-left leading-none pr-4 pl-0 flex items-center hover:bg-white hover:text-black" aria-label="home page link"><svg height="20" viewBox="0 0 278 100" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M161.632 53.2837H115.472C115.918 66.4186 125.061 72.7596 133.981 72.7596C142.9 72.7596 147.806 68.6833 150.371 62.682H160.851C158.064 73.2126 148.587 81.8182 133.981 81.8182C115.026 81.8182 104.545 68.0039 104.545 50C104.545 30.7506 117.256 18.4083 133.646 18.4083C151.931 18.4083 162.97 34.0343 161.632 53.2837ZM133.646 27.2404C124.615 27.2404 116.476 32.2226 115.584 44.4516H150.928C150.705 35.846 144.35 27.2404 133.646 27.2404Z" fill="black"></path><path d="M219.201 19.4274L198.797 48.528L221.208 80.3462H209.055L192.777 57.1336L176.61 80.3462H165.014L187.09 48.9809L166.352 19.4274H178.505L193.111 40.3753L207.829 19.4274H219.201Z" fill="black"></path><path d="M266.458 54.869V51.0191C248.061 52.944 236.354 55.6616 236.354 64.0408C236.354 69.8156 240.702 73.6655 247.949 73.6655C257.426 73.6655 266.458 69.2494 266.458 54.869ZM245.719 81.8182C234.458 81.8182 225.092 75.4772 225.092 64.2672C225.092 49.8868 241.036 45.6972 265.677 42.8664V41.3944C265.677 30.2976 259.545 26.561 252.075 26.561C243.712 26.561 238.806 31.2035 238.36 38.6768H227.88C228.883 25.5419 240.256 18.1818 251.963 18.1818C268.465 18.1818 275.935 26.2213 275.823 43.3193L275.712 57.3601C275.6 67.551 276.158 74.5713 277.273 80.3462H267.015C266.681 78.0815 266.346 75.5904 266.235 71.967C262.555 78.1948 256.311 81.8182 245.719 81.8182Z" fill="black"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M0 0H78.1818V7.46269L44.8165 50L78.1818 92.5373V100H0V0ZM39.5825 43.1172L66.6956 7.46269H12.4695L39.5825 43.1172ZM8.79612 16.3977V46.2687H31.5111L8.79612 16.3977ZM31.5111 53.7313H8.79612V83.6023L31.5111 53.7313ZM12.4695 92.5373L39.5825 56.8828L66.6956 92.5373H12.4695Z" fill="#1F40ED"></path></svg></a><div class="absolute left-1/2 transform -translate-x-1/2"><div class="relative flex gap-3 h-full"><div class="flex items-center justify-center h-full text-center cursor-pointer text-gray-700 hover:text-black px-3 py-1 text-[15px] font-normal leading-6 rounded-[4px] transition-colors hover:bg-gray-100"><span class="flex items-center gap-1">Products<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down w-3 h-3 transition-transform duration-200 "><path d="m6 9 6 6 6-6"></path></svg></span></div><div class="flex items-center justify-center h-full text-center cursor-pointer text-gray-700 hover:text-black px-3 py-1 text-[15px] font-normal leading-6 rounded-[4px] transition-colors hover:bg-gray-100"><span class="flex items-center gap-1">Company<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down w-3 h-3 transition-transform duration-200 "><path d="m6 9 6 6 6-6"></path></svg></span></div><div class="flex items-center justify-center h-full text-center cursor-pointer text-gray-700 hover:text-black px-3 py-1 text-[15px] font-normal leading-6 rounded-[4px] transition-colors hover:bg-gray-100"><span class="flex items-center gap-1">Developers<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down w-3 h-3 transition-transform duration-200 "><path d="m6 9 6 6 6-6"></path></svg></span></div><div class="flex items-center justify-center h-full text-center cursor-pointer text-gray-700 hover:text-black px-3 py-1 text-[15px] font-normal leading-6 rounded-[4px] transition-colors hover:bg-gray-100"><span class="flex items-center gap-1">Pricing<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down w-3 h-3 transition-transform duration-200 "><path d="m6 9 6 6 6-6"></path></svg></span></div><a href="https://docs.exa.ai/examples/getting-started" target="_blank" rel="noopener noreferrer" class="flex items-center justify-center h-full text-center cursor-pointer text-gray-700 hover:text-black px-3 py-1 text-[15px] font-normal leading-6 rounded-[4px] transition-colors hover:bg-gray-100">Docs</a><a href="/contact" class="flex items-center justify-center h-full text-center cursor-pointer text-gray-700 hover:text-black px-3 py-1 text-[15px] font-normal leading-6 rounded-[4px] transition-colors hover:bg-gray-100">Contact</a><div class="absolute top-full left-1/2 z-50 transition-all duration-300 ease-in-out opacity-0 pointer-events-none" style="width: 600px; transform: translateX(-50%) perspective(1000px) rotateX(-15deg); transform-origin: center top;"><div class="w-full h-[5px] relative z-10"></div><div class="bg-white shadow-lg border border-gray-200 overflow-hidden rounded-[6px]"><div class="relative transition-all duration-300 ease-in-out" style="height: 200px;"><div class="flex h-full px-[10px] " style="transform: translateX(0px);"><div class="flex-shrink-0 px-0 transition-opacity duration-300 ease-in-out py-[10px]" style="width: 650px; opacity: 0; pointer-events: none;"><div class="w-full h-full"></div></div><div class="flex-shrink-0 px-0 transition-opacity duration-300 ease-in-out py-[10px]" style="width: 580px; opacity: 0; pointer-events: none;"><div class="w-full h-full"></div></div><div class="flex-shrink-0 px-0 transition-opacity duration-300 ease-in-out py-[10px]" style="width: 580px; opacity: 0; pointer-events: none;"><div class="w-full h-full"></div></div><div class="flex-shrink-0 px-0 transition-opacity duration-300 ease-in-out py-[10px]" style="width: 450px; opacity: 0; pointer-events: none;"><div class="w-full h-full"></div></div><div class="flex-shrink-0 px-0 transition-opacity duration-300 ease-in-out py-[10px]" style="width: 580px; opacity: 0; pointer-events: none;"><div class="w-full h-full"></div></div><div class="flex-shrink-0 px-0 transition-opacity duration-300 ease-in-out py-[10px]" style="width: 580px; opacity: 0; pointer-events: none;"><div class="w-full h-full"></div></div></div></div></div></div></div></div><div class="flex items-center gap-1.5"><a href="https://exa.ai/websets" target="_blank" class="inline-block group-hover-link px-2.5 py-1.5 bg-white border border-gray-200 text-black font-['SuisseIntl'] text-[13px] hover:bg-gray-100 transition-colors rounded-[4px] flex items-center gap-1">Websets<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right w-3 h-3"><path d="m9 18 6-6-6-6"></path></svg></a><a href="https://dashboard.exa.ai" target="_blank" class="inline-block group-hover-link px-2.5 py-1.5 bg-black text-white font-['SuisseIntl'] text-[13px] hover:bg-gray-800 transition-colors rounded-[4px] flex items-center gap-1">API Dashboard<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right w-3 h-3"><path d="m9 18 6-6-6-6"></path></svg></a></div></div></div></nav></div><div class="Cover__StyledCover-sc-a18985d4-0 fBbYRN"><img class="cover-img" src="https://exa.imgix.net/search_quality_graphs_smaller.png" alt="How we do evals at Exa"><div class="Cover__BlackGrid-sc-a18985d4-1 hLiAmo"><h2>How we do evals at Exa</h2><p class="subtext">We're state of the art at search for LLMs. But how do we measure that?</p><div class="tags"><div class="CategoryTag__StyledCategoryTag-sc-a787b829-0 fCvRL engineering">engineering</div></div></div></div><div class="Containers__Main-sc-e11d2960-1 evDGyI"><div class="Containers__Content-sc-e11d2960-0 eFxpav"><section class="Byline__StyledByline-sc-974741f0-0 jGRUne"><div class="Byline__LeftSection-sc-974741f0-1 jlPvRK"><div class="Authors__Container-sc-3cb0775f-0 eubeGn"><p class="Monospace__Sm-sc-c81b4fe3-1 jIZDkn" style="color: var(--text-light-muted);">WRITTEN BY</p><div class="Authors__AuthorList-sc-3cb0775f-1 dgFTtj"><a href="https://www.linkedin.com/in/michael-fine-4b073545/" target="_blank" class="Authors__AuthorElement-sc-3cb0775f-2 lnJngA"><img src="https://exa.imgix.net/michael.jpeg" alt="Michael Fine" class="Authors__AuthorImg-sc-3cb0775f-3 gFcsAy"><p class="Text-sc-96d9c6cd-0 Authors__AuthorName-sc-3cb0775f-4 kgbZtr jrruQf link">Michael Fine</p></a></div></div><div class="PublishDate__Container-sc-35cd879d-0 ivGgcJ"><p class="Monospace__Sm-sc-c81b4fe3-1 jIZDkn" style="color: var(--text-light-muted);">PUBLISHED ON</p><p class="PublishDate__DateDisplay-sc-35cd879d-1 eopkln">May 30, 2025</p></div></div><div class="ShareButtons__StyledShareButtons-sc-ae53afeb-0 euJPps"><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fexa.ai%2Fblog%2Fevals-at-exa&amp;text=Check%20out%20this%20post%20by%20Exa%20about%20how%20we%20do%20evals%20at%20exa" target="_blank" rel="noopener noreferrer" class="ShareButtons__LinkButton-sc-ae53afeb-1 eVLHmA"><svg width="32" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0.640977 0.599976L7.12726 9.86614L0.600098 17.4H2.06922L7.78387 10.8038L12.401 17.4H17.4001L10.5487 7.6127L16.6242 0.599976H15.1551L9.8924 6.6747L5.6401 0.599976H0.640977ZM2.80138 1.75606H5.09795L15.2394 16.2439H12.9428L2.80138 1.75606Z" fill="currentColor"></path></svg></a><a class="ShareButtons__LinkButton-sc-ae53afeb-1 eVLHmA"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fexa.ai%2Fblog%2Fevals-at-exa&amp;title=Check%20out%20this%20post%20by%20Exa%20about%20how%20we%20do%20evals%20at%20exa" target="_blank" rel="noopener noreferrer" class="ShareButtons__LinkButton-sc-ae53afeb-1 eVLHmA"><svg xmlns="http://www.w3.org/2000/svg" width="32" viewBox="0 0 20 20" fill="none"><path d="M13.3333 6.66602C14.6593 6.66602 15.9311 7.1928 16.8688 8.13048C17.8065 9.06816 18.3333 10.3399 18.3333 11.666V17.4993H14.9999V11.666C14.9999 11.224 14.8243 10.8001 14.5118 10.4875C14.1992 10.1749 13.7753 9.99935 13.3333 9.99935C12.8912 9.99935 12.4673 10.1749 12.1547 10.4875C11.8422 10.8001 11.6666 11.224 11.6666 11.666V17.4993H8.33325V11.666C8.33325 10.3399 8.86004 9.06816 9.79772 8.13048C10.7354 7.1928 12.0072 6.66602 13.3333 6.66602Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.00008 7.5H1.66675V17.5H5.00008V7.5Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3.33341 4.99935C4.25389 4.99935 5.00008 4.25316 5.00008 3.33268C5.00008 2.41221 4.25389 1.66602 3.33341 1.66602C2.41294 1.66602 1.66675 2.41221 1.66675 3.33268C1.66675 4.25316 2.41294 4.99935 3.33341 4.99935Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></a></div></section><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">Evaluating the Best Search Engine</h3><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">At Exa, we've built our own search engine from the ground up. We developed a distributed crawling/parsing system, trained custom embedding and reranking models, designed a new vector database -- all in order to build the best search engine to serve AI applications.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">When we evaluate Exa search on a variety of benchmarks, we consistently perform state of the art compared to other search APIs. Using Exa retrieval in your application should improve performance on downstream tasks.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">But what does "best" actually mean? How do you evaluate web search quality? In this post, we'll share both our evaluation results and our philosophy behind evaluating web search.</p><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">Our Evaluation Results</h3><div class="Image__ImageWrapper-sc-392605e6-0 ijEOlg"><div class="Image__Container-sc-392605e6-1 fgVfIH"><img src="https://exa.imgix.net/search_quality_graphs_2.png" alt="Grading comparison chart" class="Image__ImageStyled-sc-392605e6-3 ipbSnZ"></div></div><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Pure Result Grading</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We can evaluate search result quality by having LLM graders score the relevance and quality of results returned for different query sets. We run queries through each search engine, then pass each (query, result) pair to an LLM grader, which independently evaluates the relevance and quality of the result for the query, outputting a score between 0 and 1. The final score is the average across all queries and results.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We test on three result grading datasets:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul class="list-disc pl-6"><li>In-the-wild queries: 5,000 real de-identified queries from Exa</li><li>MS Marco Queries: 10,000 queries from the MS Marco dataset</li><li>Exa Olympiad: ~500 challenging queries we hand-crafted to test reasoning and deep knowledge</li></ul></p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">The results show Exa (dark blue) performing the best across each query set. Notably, our advantage is most pronounced on the challenging Olympiad dataset, because complex queries require semantic understanding where our architecture excels.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">RAG Grading</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We can also evaluate search quality by how much it enhances LLM question-answering. We can use <a href="https://openai.com/index/introducing-simpleqa/" target="_blank">SimpleQA</a>, where an LLM agent must answer factual questions using search results.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We pass each question to an LLM, which calls the given search engine multiple times in a loop until it outputs the final answer. We then grade whether the LLM correctly outputs the expected answer using another LLM with the <a href="https://github.com/openai/simple-evals/blob/main/simpleqa_eval.py" target="_blank">SimpleQA grader prompt</a> provided by OpenAI. The score is the fraction of questions correctly answered by the LLM + search agent.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Here, Exa achieves the highest performance, meaning our full search allows LLMs to produce more factually grounded RAG outputs. (Note, we chose a simple prompt to minimize bias across search engines, so this is not our SoTA simpleQA score)</p><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">Our Evaluation Philosophy</h3><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Now we'll take a step back to explore how we approach search evals from first principles.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">What Good Evaluations Should Measure</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Fundamentally, we believe an evaluation of retrieval should actually incorporate downstream tasks based on that retrieval. This might look like:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul class="list-disc pl-6"><li>Providing a coding agent with retrieval over docs so it can use libraries and debug errors from the web</li><li>Enabling a chatbot to retrieve over the web to answer questions about real-time events in the world, or answer long-tail questions that require information not available in the LLM weights</li><li>Finding related papers to help explore a new research agenda</li><li>Determining the right product to buy</li><li>Sourcing good candidates to hire</li></ul></p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">The platonic ideal of an evaluation is simple—test how well the system accomplishes that downstream task with different retrieval systems, or with no retrieval at all. If the task is well defined enough, and the system modular enough, this is the north star—it answers exactly how well the retrieval system performs.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">However, we've found that pinning down accuracy on downstream tasks is often hard, expensive, or intractable. In some domains, like coding agents, it's possible to define a (somewhat) objective ground truth, like SWE-Bench. In others, like using retrieval in a general chatbot system, any evaluation of the quality of the answers is necessarily imperfect or limited. Any answer to evaluating search engines that reduces to evaluating LLM output is bottlenecked by our ability to evaluate LLM output—and the perpetual debate on LLM evals shows us how limiting that bottleneck is.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Even when we can define a good downstream objective to evaluate, there are still practical reasons why this only provides a limited picture. Performance with retrieval on a downstream task gives a scalar value for how well the system as a whole uses retrieval, but it can't answer many of the fine-grained questions we need to actually iterate on a retrieval system.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Suppose a coding agent has access to two different search tools, and we find that the agent with search A does 3 percentage points better on SWE-Bench than the agent with search B. Great! It seems we should use search A.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">But using search isn't just a binary choice—this number obscures important questions that are deeply relevant if we want to continue to improve:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul class="list-disc pl-6"><li>Is the coding agent calling search enough, or at the right time?</li><li>Are the queries the agent issues well tailored for the search engines?</li><li>Are the webpages returned by the search engine relevant to the queries it asks?</li><li>Does the page content returned by the search engine contain the chunks of information necessary, or is the scraping/chunking the bottleneck?</li><li>What categories of query does each search engine do well at—perhaps we should use both in concert?</li></ul></p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">These questions are important for us to answer, to determine how to improve our search, but they're also necessary for understanding what makes search valuable.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">For these two reasons—evaluating downstream tasks is often hard or infeasible, and scalar scores on downstream tasks don't provide granular enough feedback to iterate—we've found it necessary to evaluate retrieval beyond how it performs as part of a larger system.</p><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">MS Marco Myopia</h3><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">In the rich information retrieval literature, retrieval is traditionally evaluated by what we'll call<b>"closed evals"</b>. MS Marco is a representative example.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">MS Marco consists of three components:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul><li>A query set of 1 million Bing user queries</li><li>A fixed document corpus of 3.2 million passage snippets</li><li>Binary human labels for each query, indicating which passage is relevant</li></ul></p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Retrieval systems are evaluated on MS Marco by retrieving the top passages for each query, and reporting metrics like MRR: over all queries, what is the average position in the retrieved results of the first document marked by the human labelers as relevant.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">While MS Marco is now retired for new submissions, its structure is representative of many similar closed datasets. Other common closed evals include BEIR (the retrieval subset) or Trivia QA.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Closed evals have some important benefits. By holding the index and grades constant, you're able to compare different retrieval methods (like BM25 or embedding models) in a reproducible way.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">False Negatives</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Scores on MS Marco are determined by how often your model output agrees with the human labelers' choice of the most relevant document. However, as we've seen, and as&nbsp;<a href="https://arxiv.org/pdf/2109.00062" target="_blank" rel="noopener noreferrer">Arabzadeh et al.</a>&nbsp;noted, these scores have many false negatives. Often, the top documents a model returns are listed as irrelevant, but both human and LLM judges rate those documents as higher relevance than the top document as labeled by humans.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">This is not saying that MS Marco has bad human labelers. Fundamentally, for a corpus of millions of documents, it is infeasible for humans (and even LLMs) to accurately label each document for each query—that relevance matrix would be 1 million × 3.2 million = 3.2 trillion labels.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Instead, labels must be sparse. Typically closed evals are constructed by approximately retrieving candidate documents, and having humans select the top document from that. But this is upper bounded then by the quality of the initial approximate retrieval—if a true positive was never even shown to the human labelers, it will be labeled as a negative, regardless whether the human labelers would've selected it.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Scale Matters</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">One way to solve this false negative problem is to reduce the corpus size. Many closed evals are like this, including MS Marco Passage Ranking. Instead of a shared corpus of millions of documents, each query has a small (~50) independent corpus of documents, again labeled positive or negative for that query.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">This makes it much more feasible to avoid false negatives, because humans can feasibly grade every document for each query. As always, it is still possible for the labels to be wrong, but the small scale makes this much less likely.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">However, this comes with a steep price. Our goal is to see how often the model can pick the correct document out of ~50 documents, and use that as a proxy for what we actually care about, which is how often the model will select the platonic correct document out of a web-sized index, of billions of documents. But at Exa we've seen in practice that this is an imperfect proxy: performance at small scales doesn't necessarily hold at large scale.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><a href="https://aclanthology.org/2021.acl-short.77.pdf" target="_blank" rel="noopener noreferrer">Reimers et al.</a>&nbsp;investigate this as well, showing theoretically and empirically that dense embedding model performance decreases faster than sparse models' with respect to index size. We've seen this not only in comparing dense vs sparse models, but also even within different models. This is also an artifact of how embedding models are trained—in training, the effective corpus size is determined by the batch size, which is typically much smaller than the production corpus size. We've done a lot of research at Exa into mitigating this, but the problem still remains—better retrieval over 3.2 million documents might not be better over billions.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Closed Evals Need White-Box Access</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">By definition, closed evals require controlling which documents you retrieve over. A positive label for a document for a given query does not mean that this is the theoretically optimal document, merely that it is the best document of the documents in the corpus.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">But when picking a general web search API, you don't have control over which documents you retrieve over. Instead, the search provider retrieves over all documents in their index, which is certainly larger than the 3.2 million MS Marco corpus, and may not even contain all documents in the corpus.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Thus, even ignoring the within-corpus false negative problem from above, a metric like MRR doesn't make sense when retrieving from a general web search API. If the labeled positive document appears in position 10, the 9 above may in fact be better than the MS MARCO labeled positive. The labels, by definition, can't tell you about documents not in the labels, and naively using MRR may simply be penalizing a web search API for having a larger, and better index.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">MS Marco Is Not the Distribution We Care About</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">A good eval should answer the question: on the queries we care about, how well does a retriever perform. But MS Marco (or any closed eval) is likely not the exact distribution of queries that are relevant for our use cases. They're taken from users' Bing searches, from before 2020. If we're interested in evaluating performance on recent searches, or different languages, or multiple clause complex queries, or about specific domains like coding, those types of queries are certainly underrepresented in the distribution, and may not even be present at all.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Indeed, we've found it's often quite tractable to obtain more relevant queries. When we have an existing system, there's no substitute for simply sampling from actual queries. Even when that's not feasible, writing a representative set of ~100 search queries can easily be done in a couple hours—we do this often at Exa.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">However, the challenge with closed datasets is that while obtaining the queries is feasible, labeling each document as relevant or not is often very time intensive—which is why there are relatively so few large closed IR datasets. We've found that for complex, knowledge intensive queries, evaluating whether a document is correct can take anywhere from 10 seconds to 30 minutes per document—generating labels on the scale of MS Marco would take thousands or millions of person-hours.</p><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">Our Approach: Open Evaluations</h3><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We've argued in the prior section that closed evals, while scientifically principled, can't capture how well a search provider would perform in a real world setting.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We were originally motivated by the problem of scale and false negatives—we wanted to evaluate over indexes in the billions, where determining the complete set of positive documents would be practically infeasible.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Now, for some queries, you could imagine setting a single labeled positive document:&nbsp;<code class="Utils__InlineCode-sc-8d535c92-10 eoireQ">"wikipedia page of the runner up in the 1960 democratic primary"</code>. Here there's one good document: Lyndon B Johnson's Wikipedia page. We can be confident that any another document is worse. However, for most queries, there isn't a sole objective answer—consider&nbsp;<code class="Utils__InlineCode-sc-8d535c92-10 eoireQ">"best blog posts about evals"</code>—this is an ever-changing set, where the only way to determine if a result is better than other ones is by looking at each result.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Instead, at Exa we've moved to what we call "open evals"—open because unlike closed evals, they're not designed with a fixed index. An open eval simply is a list of queries, which can be run over any index. Defined this way, it feels almost trivial to give this a name, but it has important consequences.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">As we noted above, for a massive, non-fixed index, we can't specify the labeled positive documents. Instead, we take advantage of LLM labelers. An open eval is always graded by an LLM. Thus, the flow of an LLM evaluation is simple:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul><li>Define queries</li><li>Choose a search provider</li><li>Search the queries</li><li>For each query, document result, prompt an LLM to give a scalar relevance grade</li><li>Report the aggregate relevance score</li></ul></p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">This has some downsides, as we'll note, but has a number of important advantages:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul><li>We can now evaluate on black box search providers, without needing to specify the index</li><li>It's efficient to run on massive indexes</li><li>Much less labor intensive to create evals—you only have to specify the queries</li><li>Works naturally not just for grading raw search results, but also LLM outputs from those results</li></ul></p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">However, this has tradeoffs. This is the same flow as grading LLM outputs—at a high level, it's just a prompt+black box output → LLM grade—and shares all the challenges of LLM evaluation:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul><li><strong>Expensive to run</strong>: We now need to pass up to 1000s of tokens per document to an LLM, with multiple documents per query</li><li><strong>More grading variance</strong>: This introduces non-determinism from the LLM, as well as non-determinism from hitting production systems. Both can be mitigated, but fundamentally is less reproducible</li><li><strong>Heavily dependent on the grading prompt</strong>: This essentially reduces down to how well the LLM grading prompt matches human (or agent) preferences. There's lots of work involved, but thanks to the capacity of LLMs luckily we found it's very much an 80/20 scenario—most reasonable prompts work, for most grading tasks</li><li><strong>Verification gap</strong>: Even with a good prompt, there's a bit of a mismatch here. Fundamentally, the point of retrieval is to provide information that the LLM doesn't already know—if an LLM knew it, we wouldn't need RAG at all. It's a little odd then, to trust an LLM to grade results that it doesn't know the right answer to. This is an important point, and we'll dwell on it in the next section</li></ul></p><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">How We Address the Verification Gap</h3><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">How did we build a system where we can trust LLM grades of things it doesn't already know the answer to? There are a few important points.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Most of Search is... Dumb</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">First, most existing search systems spend orders of magnitude less compute per document than LLMs do. This is something we're actively rectifying at Exa. But out of necessity, retrieving over billions of documents in a latency sensitive way means they can't afford much. This typically means retrieving the initial set of documents through embeddings or term matching, and then reranking with a small (&lt;1B params) reranker. Because of this, we'd expect in general to trust the ranking of raw search results less than that of a much larger LLM with both more knowledge and more tokens to spend reasoning about the document.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We can see this ourselves—Google a query like&nbsp;<code class="Utils__InlineCode-sc-8d535c92-10 eoireQ">"research papers less than 8 pages citing LeCun"</code>—the results fail in obvious ways that an LLM could detect.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Remember, our goal is not necessarily to get the platonic quality of any given document—a somewhat undefined concept. We just need a grader such that over large n, the average grade of a better retrieval system is better than that of a worse one—and the LLM's capacity advantage over retrieval systems gets us closer to that.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Most Queries Are Contextual</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Second, some queries are explicitly or implicitly dependent on external facts not present in the page, like&nbsp;<code class="Utils__InlineCode-sc-8d535c92-10 eoireQ">"university homepage of the Turing Award winner in 2004"</code>. However, a large fraction of documents either explicitly contain much of the information to determine whether it satisfies the query, or contain enough proxy signals to correlate which is the better document. This still fails sometimes, and often in correlated ways—one search engine might overindex on high quality pages, at the cost of relevance/correctness—and we want to be able to determine that!</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">In particular, we bias our query sets towards queries that can be graded contextually.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Expected Answers</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">For queries with niche factual knowledge, or specific criteria—we can just pass the expectations to the LLM grader—simply specify the criteria a good document should satisfy, or the facts an answer should contain, and prompt the LLM grader to consider that.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">One might object—providing the expected answer sounds a lot like the closed evals we were trying to avoid. But the point of removing explicit labels from the closed evals was because it was impractical to label each document in the corpus, and because providing an explicit correct document often leads to false negatives when there exist other better documents.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">By providing general facts or criteria a document should satisfy, we can allow the LLM to match the document for semantic criteria, not brittle exact matches of particular documents. This provides other benefits too—we can now get fine grained breakdowns of which searchers systematically fail certain criteria, if shared between documents.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">In conclusion, there's no silver bullet, but with a combination of powerful LLMs, good prompts, careful querying, and labeling expected answers, we've found we can get pretty far.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">As search engines improve—and as we push the bounds of Exa, where we design our search from the ground up to take advantage of LLM capabilities—different approaches will have to reign. We've found for many queries that grading Exa search results is often beyond the capacity of (bandwidth limited) humans. In later posts, we'll talk more about this --&nbsp;<a href="https://openai.com/index/introducing-superalignment/" target="_blank" rel="noopener noreferrer">Super Alignment</a> (rip) for search if you will.</p><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">Our Grading Methodology</h3><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Open evals require delegating the actual grading to LLMs. While LLMs are intelligent (in spiky ways), getting this right requires careful calibration.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Aggregation Method</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We've specified our queries, ran them through different search engines, and now have a list of <code class="Utils__InlineCode-sc-8d535c92-10 eoireQ">(query, [documents], search_engine)</code>. What should the LLM see, and how should we aggregate it? We considered three main approaches:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul><li><strong>Pointwise</strong>: Flatten the list—make an LLM output a numerical grade for each <code class="Utils__InlineCode-sc-8d535c92-10 eoireQ">(query, document)</code> pair, then group by query and average the grades</li><li><strong>Pairwise</strong>: For each query, generate all possible pairs of searchers. Pass the results for each searcher into one LLM call, asking the LLM to select the best result set. Use the pairwise win data to compute the ELO of each searcher</li><li><strong>Listwise</strong>: For each query, take the top n results from each searcher, randomly interleave them, and ask an LLM to reorder them by quality. Average the position metrics for each searcher</li></ul></p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Each method has its merits. Pointwise is simplest to run and allows more controllability over aggregation. Pairwise is more theoretically sound—it's unclear what the pointwise numerical grading scale even means. What delineates a document between 0.7 and 0.75?</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Similarly, it's not immediately clear that LLMs can output transitive consistent scores—if it gives one document a 0.6 in one call, will it definitely give a better one an 0.7? That would require it to have an understanding of the distribution of result quality. By doing relative comparisons, pairwise solves this.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Listwise shares the same relative grading benefits as pairwise, with O(n) LLM calls, at the cost of much larger context—it's a challenging task that LLMs can't do perfectly. In addition, putting all the documents in context allows the LLM to use information from other documents to help grade each other, and evaluate diversity as well as pointwise quality.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">In short, in theory we've concluded that pairwise probably gives the most consistent scores, while pointwise is the easiest to run and interpret.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">However, we've found despite its theoretical limitations, the results of pointwise evals tend to really closely track the results of pairwise evals. In most cases we default to pointwise, but occasionally look at pairwise.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Aggregating Pointwise Scores</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Once we have individual scores for each result, we need to aggregate them into a score per query. We've experimented with several approaches:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ul><li><strong>Mean</strong>: Simple average of all result scores</li><li><strong>Median</strong>: Middle score, robust to outliers</li><li><strong>Rank-weighted mean</strong>: Sum of score/rank², giving more weight to top results</li><li><strong>NDCG</strong>: Normalized Discounted Cumulative Gain, a standard IR metric that heavily weights top positions</li></ul></p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Each metric emphasizes different aspects of search quality. Mean treats all results equally, median provides robustness against particularly bad results, rank-weighted metrics emphasize top result quality, and NDCG is the most aggressive in prioritizing the first few results.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Interestingly, we've found that over large numbers of queries, the relative ordering of search engines remains fairly constant across these aggregation methods. This consistency suggests our performance differences are robust and not artifacts of any particular metric choice. We report mean scores for simplicity and interpretability, but have confidence this reflects genuine quality differences.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Number of Results</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We evaluate the top 5 results per query for computational efficiency. Our testing showed high agreement between evaluating 5, 10, and 20 results—the relative performance between search engines remains consistent regardless of depth.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Grading Prompt</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Determining the prompt for grading is where we spent much of our time—all the clever aggregation, visualizations, or queries can't overcome a grader that doesn't track with what we care about.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">The only way to pin this down was by careful iteration. We started with the standard ingredients for a good prompt: clear instructions with core principles, examples, chain of thought or reasoning, and then saw how it did. We built a tool to make it easy to create human preferences on search results in order to validate and iterate on our prompt, and found that after a lot of iteration, our refined prompt matched human preferences 97% of the time on easy examples, and 83% on hard/ambiguous ones—close to how much different humans agreed with each other.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">The full prompt we use for internal use is:</p><div class="CodeSnippet-sc-2dc0d1c2-0 jErBsR"><span style="font-size: inherit; font-family: var(--font-family-monospace); background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: var(--gray-800); color: rgb(171, 178, 191); border-radius: 3px; display: flex; line-height: 1.42857; overflow-x: auto; white-space: pre; padding: 16px 12px;"><code style="white-space: pre; font-size: inherit; font-family: inherit; line-height: 1.66667; padding: 8px;"><span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">1</span><span>You are a helpful assistant that grades the relevance of search results for given queries.
</span><span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">2</span>Your task is to assign a relevance score between 0.0 and 1.0 to each result, where:
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">3</span>
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">4</span>1.0: Perfect match - The result provides exactly what was asked for with high quality and authority
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">5</span>0.8-0.9: Excellent match - Very relevant and high quality, with minor imperfections
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">6</span>0.6-0.7: Good match - Clearly relevant but may be missing some aspects or quality issues
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">7</span>0.4-0.5: Fair match - Partially relevant but significant gaps or quality concerns
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">8</span>0.2-0.3: Poor match - Only tangentially related or major quality issues
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">9</span>0.0-0.1: Irrelevant - Does not meaningfully address the query
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">10</span>
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">11</span>Key scoring principles:
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">12</span>- We want exact matches to the user's query - if they ask for a specific entity or type of information, that's what we need
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">13</span>- Lists or general articles about a topic are not good matches when the user wants a specific entity
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">14</span>- Consider both relevance to the query AND the quality/authority of the source
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">15</span>- Use decimal points for fine-grained differentiation (e.g. 0.85 vs 0.82)
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">16</span>- Be consistent in your scoring across different queries
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">17</span>
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">18</span>KEEP in mind -- you are seeing a (sometimes truncated) snippet of the result, and results may not necessarily have all the information necessary to determine
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">19</span>whether they match the query. For example, if the query is "companies founded after 2020", a company homepage is a good result, even if the homepage doesn't mention the year.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">20</span>Use your judgement and knowledge of the query and the result to make the best determination.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">21</span>
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">22</span>Above all else, your job is to use your judgement to determine what would be a good search result for a user interested in direct links to their, sometimes complex queries. USE YOUR JUDGEMENT.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">23</span>
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">24</span># Criteria Descriptions:
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">25</span># 
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">26</span># 1. query_relevance: This measures how well the search result matches the user's query. A high score means the result directly and fully answers the query, while a low score means the result is only tangentially related or irrelevant.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">27</span># 
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">28</span># 2. result_quality: This assesses the authority, accuracy, and trustworthiness of the result. High-quality results come from reputable sources, are well-written, and are not spammy or misleading.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">29</span># 
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">30</span># 3. content_issues: This is a boolean indicating whether there are problems with the content, such as truncation, missing information, or improper parsing. If the result is incomplete or garbled, set this to True.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">31</span># 
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">32</span># 4. confidence: This reflects how certain you are about your grading. If the result snippet is clear and directly answers the query, confidence should be high. If you need external information to validate whether the result is a good match for the query, your confidence should be lower.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">33</span># 
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">34</span># 5. score: This is your overall assessment of the result, on a scale from 0.0 (irrelevant) to 1.0 (perfect match), taking into account both relevance and quality.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">35</span># 
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">36</span># Instructions:
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">37</span># 
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">38</span># For each search result, carefully read the query and the result. Assign a value for each criterion as follows:
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">39</span># - Provide a brief explanation of your reasoning.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">40</span># - Assign a query_relevance score between 0.0 and 1.0.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">41</span># - Assign a result_quality score between 0.0 and 1.0.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">42</span># - Indicate if there are any content_issues (True/False).
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">43</span># - Assign a confidence score between 0.0 and 1.0.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">44</span># - Assign an overall score between 0.0 and 1.0.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">45</span># 
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">46</span># Be consistent and use decimal points for fine-grained differentiation. If you are unsure due to missing or unclear information, lower your confidence and make a best guess as to the score.</code></span></div><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">However, in order to avoid unintentionally biasing results, we've run these evals with a much more minimal prompt, which we’ve found to have high correlation with the gold standard prompt above:</p><div class="CodeSnippet-sc-2dc0d1c2-0 jErBsR"><span style="font-size: inherit; font-family: var(--font-family-monospace); background-image: initial; background-position: initial; background-size: initial; background-repeat: initial; background-attachment: initial; background-origin: initial; background-clip: initial; background-color: var(--gray-800); color: rgb(171, 178, 191); border-radius: 3px; display: flex; line-height: 1.42857; overflow-x: auto; white-space: pre; padding: 16px 12px;"><code style="white-space: pre; font-size: inherit; font-family: inherit; line-height: 1.66667; padding: 8px;"><span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">1</span><span>You are a helpful assistant that grades the relevance of search results for given queries.
</span><span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">2</span>Your task is to assign a relevance score between 0.0 and 1.0 to each result, based on how good a result is for the query.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">3</span>
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">4</span>For each search result, carefully read the query and the result. Assign a value for each criterion as follows:
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">5</span>- Provide a brief explanation of your reasoning.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">6</span>- Assign a query_relevance score between 0.0 and 1.0.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">7</span>- Assign a result_quality score between 0.0 and 1.0.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">8</span>- Indicate if there are any content_issues (True/False).
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">9</span>- Assign a confidence score between 0.0 and 1.0.
<span class="linenumber react-syntax-highlighter-line-number" style="display: inline-block; min-width: 2.25em; padding-right: 1em; text-align: right; user-select: none; color: rgb(92, 99, 112); font-family: inherit; font-style: italic;">10</span>- Assign an overall score between 0.0 and 1.0.</code></span></div><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Model Selection</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We use GPT-4.1 for grading. While absolute scores vary between models, we found high ranking agreement between GPT-4o, GPT-4o-mini, GPT-4.1, and Gemini Flash 2.5. This consistency indicates rankings reflect quality differences rather than model-specific biases.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">While most other search engines return snippets as content, Exa returns lots of page contents per result. For RAG applications, snippets often miss critical context, making them less useful even if they seem relevant. However, we evaluate what users actually receive from each API to ensure fair comparison.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We've also run experiments normalizing content—using Exa's content for all search engines' results. While this increases other engines' scores, Exa's advantage persists, showing our edge comes from better retrieval, not just better content extraction.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">An interesting finding: for many queries, LLM grading based solely on URL and title correlates highly with full-text grading. However, this correlation breaks down for subtle, challenging queries—exactly where search quality matters most.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Handling Failures</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Production search systems occasionally fail. We retry failed queries up to 5 times with exponential backoff. Queries where any engine fails all retries are excluded from results.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">API Configuration</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Apart from result count and content settings, we use default API parameters for all search engines. This reflects how most users interact with these services and avoids cherry-picking configurations that might favor particular approaches.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Statistical Rigor</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Eval scores are inherently a random variable. We find it really useful to report confidence intervals around any aggregation, in order to get intuition for the effect sizes of the difference in score. See <a href="https://www.anthropic.com/research/statistical-approach-to-model-evals" target="_blank">this paper</a> for an accessible overview. Even confidence intervals, with clustered errors, doesn't perfectly capture the correlated nature of errors, but is a good start.</p><h4 class="Utils__SectionSubtitle-sc-8d535c92-8 bnHnUP">Importance of Manual Review</h4><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">If you've gotten this far, you've now read thousands of words on how we automate evals. This is indispensable if we want to make principled decisions and improvements to search systems. Getting a comprehensive picture of the performance of even a single search system requires aggregating dozens if not hundreds of queries, and making fine grained distinctions in average performance. It's not feasible to ask humans to do this, especially repeatedly.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">That said, there is still no substitute for manually running a few queries ourselves. Evals, especially LLM graded, provide a narrow and sometimes biased window into the performance of retrieval systems. I can't count the number of times manually looking at a few query results has given us insight that the evals missed.</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">This can also be helped with automation—at the very least, in our eval interface, we built an easy way to run queries through different search engines and display the results side by side.</p><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">Why This Approach Matters</h3><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">Our evaluation philosophy directly impacts how we build Exa:</p><p class="Utils__Paragraph-sc-8d535c92-9 Psryn"><ol><li><strong>Real-world optimization</strong>: By evaluating on actual query distributions over full web-scale indexes, we ensure Exa performs well on the searches that matter to users.</li><li><strong>Rapid iteration</strong>: Open evaluations let us rapidly test improvements without waiting for human labeling or being constrained by fixed corpora.</li><li><strong>Comprehensive measurement</strong>: By evaluating both result quality and downstream task performance, we ensure Exa works well both for direct search and as a tool for LLMs.</li><li><strong>Current relevance</strong>: Our evaluation approach naturally handles emerging topics and current events that fixed benchmarks miss.</li></ol></p><h3 class="Utils__SectionTitle-sc-8d535c92-7 loSIAr">Future Directions</h3><p class="Utils__Paragraph-sc-8d535c92-9 Psryn">We've released a simple subset of the evals we use to evaluate search quality. There are many more facets of search quality that we test internally, and many more ways we're actively working on testing frontier search, that matches or exceeds human (and LLM) capacity to judge. We're excited to keep sharing improved, scalable, and automated benchmarks/frameworks for judging search quality.</p><br><hr class="Utils__Hr-sc-8d535c92-2 dFEjaN"><div class="SignOff__Container-sc-8101721b-0 iZzpVa"><div class="SignOff__LeftSection-sc-8101721b-1 kMOcXe"><h4>Cheers</h4><div><h4><a href="https://www.linkedin.com/in/michael-fine-4b073545/">Michael Fine</a></h4></div></div><div class="ShareButtons__StyledShareButtons-sc-ae53afeb-0 euJPps"><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fexa.ai%2Fblog%2Fevals-at-exa&amp;text=Check%20out%20this%20post%20by%20Exa%20about%20how%20we%20do%20evals%20at%20exa" target="_blank" rel="noopener noreferrer" class="ShareButtons__LinkButton-sc-ae53afeb-1 eVLHmA"><svg width="32" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0.640977 0.599976L7.12726 9.86614L0.600098 17.4H2.06922L7.78387 10.8038L12.401 17.4H17.4001L10.5487 7.6127L16.6242 0.599976H15.1551L9.8924 6.6747L5.6401 0.599976H0.640977ZM2.80138 1.75606H5.09795L15.2394 16.2439H12.9428L2.80138 1.75606Z" fill="currentColor"></path></svg></a><a class="ShareButtons__LinkButton-sc-ae53afeb-1 eVLHmA"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fexa.ai%2Fblog%2Fevals-at-exa&amp;title=Check%20out%20this%20post%20by%20Exa%20about%20how%20we%20do%20evals%20at%20exa" target="_blank" rel="noopener noreferrer" class="ShareButtons__LinkButton-sc-ae53afeb-1 eVLHmA"><svg xmlns="http://www.w3.org/2000/svg" width="32" viewBox="0 0 20 20" fill="none"><path d="M13.3333 6.66602C14.6593 6.66602 15.9311 7.1928 16.8688 8.13048C17.8065 9.06816 18.3333 10.3399 18.3333 11.666V17.4993H14.9999V11.666C14.9999 11.224 14.8243 10.8001 14.5118 10.4875C14.1992 10.1749 13.7753 9.99935 13.3333 9.99935C12.8912 9.99935 12.4673 10.1749 12.1547 10.4875C11.8422 10.8001 11.6666 11.224 11.6666 11.666V17.4993H8.33325V11.666C8.33325 10.3399 8.86004 9.06816 9.79772 8.13048C10.7354 7.1928 12.0072 6.66602 13.3333 6.66602Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.00008 7.5H1.66675V17.5H5.00008V7.5Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3.33341 4.99935C4.25389 4.99935 5.00008 4.25316 5.00008 3.33268C5.00008 2.41221 4.25389 1.66602 3.33341 1.66602C2.41294 1.66602 1.66675 2.41221 1.66675 3.33268C1.66675 4.25316 2.41294 4.99935 3.33341 4.99935Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></a></div></div><div class="SeeMore__Container-sc-df78e18b-0 cSRexr"><p class="Monospace__Lg-sc-c81b4fe3-4 QGbSv">SEE MORE</p><div class="SeeMore__CardContainer-sc-df78e18b-1 cKulHB"><a href="/blog/zdr-search-engine" target="" class="BlogCard__Container-sc-7ca9786c-0 bsiYCX"><img src="https://exa.imgix.net/zdr-shield.png" alt="Zero Data Retention across Exa Search Products" class="BlogCard__CoverImage-sc-7ca9786c-1 kewfGD"><div class="BlogCard__MetadataContainer-sc-7ca9786c-2 gdYXKm"><h4 class="Heading__H4-sc-f956f9ef-3 BlogCard__Title-sc-7ca9786c-3 dmqDFj hpoUyR">Zero Data Retention across Exa Search Products</h4><p class="Text-sc-96d9c6cd-0 Text__Monospace-sc-96d9c6cd-1 BlogCard__Subtext-sc-7ca9786c-4 kgbZtr hFaMPd eEZvaL">Enterprises can now do things like private deep research reports</p><div class="BlogCard__Metadata-sc-7ca9786c-5 dKwrUD"><div class="BlogCard__AuthorContainer-sc-7ca9786c-6 hXdYUO"><img src="https://exa.imgix.net/willbryk.JPG" alt="By Will Bryk" class="BlogCard__AuthorImage-sc-7ca9786c-7 eeFTUd"><p class="Text-sc-96d9c6cd-0 BlogCard__MetaText-sc-7ca9786c-8 kgbZtr geXpIi">Will Bryk</p></div><p class="Text-sc-96d9c6cd-0 BlogCard__MetaText-sc-7ca9786c-8 kgbZtr geXpIi">August 17, 2025</p></div></div></a><a href="/blog/fastest-search-api" target="" class="BlogCard__Container-sc-7ca9786c-0 bsiYCX"><img src="https://exa.imgix.net/search_api_graph_multiplebars.png" alt="The world's fastest search API" class="BlogCard__CoverImage-sc-7ca9786c-1 kewfGD"><div class="BlogCard__MetadataContainer-sc-7ca9786c-2 gdYXKm"><h4 class="Heading__H4-sc-f956f9ef-3 BlogCard__Title-sc-7ca9786c-3 dmqDFj hpoUyR">The world's fastest search API</h4><p class="Text-sc-96d9c6cd-0 Text__Monospace-sc-96d9c6cd-1 BlogCard__Subtext-sc-7ca9786c-4 kgbZtr hFaMPd eEZvaL">AI systems need faster search than humans. They now have it.</p><div class="BlogCard__Metadata-sc-7ca9786c-5 dKwrUD"><div class="BlogCard__AuthorContainer-sc-7ca9786c-6 hXdYUO"><img src="https://exa.imgix.net/willbryk.JPG" alt="By Will Bryk" class="BlogCard__AuthorImage-sc-7ca9786c-7 eeFTUd"><p class="Text-sc-96d9c6cd-0 BlogCard__MetaText-sc-7ca9786c-8 kgbZtr geXpIi">Will Bryk</p></div><p class="Text-sc-96d9c6cd-0 BlogCard__MetaText-sc-7ca9786c-8 kgbZtr geXpIi">July 28, 2025</p></div></div></a><a href="/blog/flatfile-exa" target="" class="BlogCard__Container-sc-7ca9786c-0 bsiYCX"><img src="/images/case-studies/flatfile-exa.png" alt="Flatfile" class="BlogCard__CoverImage-sc-7ca9786c-1 kewfGD"><div class="BlogCard__MetadataContainer-sc-7ca9786c-2 gdYXKm"><h4 class="Heading__H4-sc-f956f9ef-3 BlogCard__Title-sc-7ca9786c-3 dmqDFj hpoUyR">Flatfile</h4><p class="Text-sc-96d9c6cd-0 Text__Monospace-sc-96d9c6cd-1 BlogCard__Subtext-sc-7ca9786c-4 kgbZtr hFaMPd eEZvaL">High quality market &amp; people research powered by Websets API</p><div class="BlogCard__Metadata-sc-7ca9786c-5 dKwrUD"><div class="BlogCard__AuthorContainer-sc-7ca9786c-6 hXdYUO"><img src="https://exa.imgix.net/logo_cream.png" alt="By The Exa Team" class="BlogCard__AuthorImage-sc-7ca9786c-7 eeFTUd"><p class="Text-sc-96d9c6cd-0 BlogCard__MetaText-sc-7ca9786c-8 kgbZtr geXpIi">The Exa Team</p></div><p class="Text-sc-96d9c6cd-0 BlogCard__MetaText-sc-7ca9786c-8 kgbZtr geXpIi">June 24, 2025</p></div></div></a></div></div></div></div><footer class="text-white font-sans flex w-full justify-center items-start gap-2.5 relative overflow-hidden z-10 md:flex-col md:p-10 sm:p-7.5" style="background: linear-gradient(45deg, rgb(0, 66, 180) 0%, rgb(0, 0, 152) 25%, rgb(2, 2, 116) 50%, rgb(3, 3, 99) 75%, rgb(4, 4, 105) 100%);"><div class="w-full max-w-[1000px] mx-auto pt-28 pb-10 flex flex-col justify-between items-start gap-10 px-[25px] md:px-4 z-10 md:px-5 sm:px-3.75 sm:gap-7.5"><div class="flex flex-col items-start gap-7.5 mb-5"><h2 class="text-4xl md:text-5xl leading-[34pt] md:leading-[44pt] gap-2 font-normal mb-10">Imagine a world with perfect search... <br>or help build it</h2><div class="flex gap-4 mb-7.5"><a href="/about" class="group-hover-link px-[16px] py-[10px] bg-white text-[#262DD7] text-md font-mono flex items-center gap-2 group outline-2 outline-[#262DD7]">About the team<div class="relative w-4 h-4 flex items-center justify-center  "><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right arrow-slide-out w-4 h-4"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right arrow-slide-in w-4 h-4"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></div></a><a href="/contact" class="group-hover-link px-[16px] py-[10px] bg-white text-[#262DD7] text-md font-mono flex items-center gap-2 group outline-2 outline-[#262DD7]">Talk to us<div class="relative w-4 h-4 flex items-center justify-center  "><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right arrow-slide-out w-4 h-4"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right arrow-slide-in w-4 h-4"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></div></a></div></div><div class="flex flex-row flex-wrap gap-y-8 gap-x-12 w-full md:gap-8 md:flex-nowrap"><div class="flex flex-col items-start w-2/5 md:flex-1 md:w-auto"><div class="flex flex-col"><span class="text-white text-xl font-['Reckless-Regular']">Company</span></div><ul class="m-0 p-0 mt-2 list-none"><li><a href="/about" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">About</a></li><li><div class="flex gap-2 flex-row sm:flex-row sm:gap-2"><a href="/careers" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Careers</a><div class="bg-white px-1 md:px-2 rounded-[2px] flex items-center justify-center"><p class="text-[9px] md:text-[12px] font-mono text-[#262DD7] font-bold md:font-medium text-center">We're hiring</p></div></div></li><li><a href="/blog" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Blog</a></li><li><a href="/contact" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Contact</a></li><li><span class="text-xs leading-[2] text-white/80 cursor-pointer hover:text-white select-all font-mono relative" title="Click to copy">hello@exa.ai</span></li><li><span class="text-xs leading-[2] text-white/80 cursor-pointer hover:text-white select-all font-mono relative" title="Click to copy">press@exa.ai</span></li></ul></div><div class="flex flex-col items-start w-2/5 md:flex-1 md:w-auto"><div class="flex flex-col"><span class="text-white text-xl font-['Reckless-Regular']">Products</span></div><ul class="m-0 p-0 mt-2 list-none"><li><a href="/exa-api" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Exa API</a></li><li><a href="https://exa.ai/websets" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Exa Websets</a></li></ul></div><div class="flex flex-col items-start w-2/5 md:flex-1 md:w-auto"><div class="flex flex-col"><span class="text-white text-xl font-['Reckless-Regular']">Developers</span></div><ul class="m-0 p-0 mt-2 list-none"><li><a href="https://dashboard.exa.ai/" target="_blank" rel="noopener noreferrer" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">API</a></li><li><a href="https://docs.exa.ai/examples/getting-started" target="_blank" rel="noopener noreferrer" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Documentation</a></li><li><a href="/demos" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Demos</a></li><li><a href="https://status.exa.ai" target="_blank" rel="noopener noreferrer" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">API Status</a></li><li><a href="https://docs.exa.ai/reference/faqs" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">FAQ</a></li></ul></div><div class="flex flex-col items-start w-2/5 md:flex-1 md:w-auto"><div class="flex flex-col"><span class="text-white text-xl font-['Reckless-Regular']">Tutorials</span></div><ul class="m-0 p-0 mt-2 list-none"><li><a href="https://docs.exa.ai/examples/recent-news-summarizer" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">News Summarizer</a></li><li><a href="https://docs.exa.ai/examples/exa-rag" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">RAG</a></li><li><a href="https://docs.exa.ai/examples/company-analyst" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Competitor Analysis</a></li><li><a href="https://docs.exa.ai/examples/exa-researcher" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Research Assistant</a></li><li><a href="https://exa.ai/websets/directory" class="text-sm leading-[2] text-white no-underline cursor-pointer hover:underline hover:underline-offset-1 font-mono">Directory</a></li></ul></div></div><div class="flex flex-col items-start gap-4 self-stretch mt-5 md:flex-row md:justify-between md:items-center"><div class="flex gap-3 justify-center ml-0 md:ml-0"><a href="https://x.com/exaailabs" target="_blank" rel="noopener noreferrer" class="text-white" aria-label="Follow us on x.com"><svg width="16" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0.640977 0.599976L7.12726 9.86614L0.600098 17.4H2.06922L7.78387 10.8038L12.401 17.4H17.4001L10.5487 7.6127L16.6242 0.599976H15.1551L9.8924 6.6747L5.6401 0.599976H0.640977ZM2.80138 1.75606H5.09795L15.2394 16.2439H12.9428L2.80138 1.75606Z" fill="currentColor"></path></svg></a><a href="https://discord.gg/HCShtBqbfV" target="_blank" rel="noopener noreferrer" class="text-white" aria-label="Check our discord"><svg width="20" viewBox="0 0 18 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M15.2477 1.17248C14.0825 0.624743 12.8367 0.22665 11.5342 0C11.3742 0.290577 11.1873 0.681402 11.0585 0.992319C9.67387 0.783107 8.30197 0.783107 6.94286 0.992319C6.81404 0.681402 6.62288 0.290577 6.46153 0C5.1576 0.22665 3.91031 0.626196 2.74515 1.17539C0.394983 4.74368 -0.242108 8.22336 0.0764375 11.6536C1.63519 12.8232 3.1458 13.5336 4.63093 13.9985C4.99762 13.4915 5.32466 12.9525 5.6064 12.3844C5.06982 12.1795 4.5559 11.9268 4.07029 11.6332C4.19913 11.5374 4.32513 11.4371 4.44689 11.334C7.40868 12.7258 10.6267 12.7258 13.5531 11.334C13.6762 11.4371 13.8022 11.5374 13.9296 11.6332C13.4426 11.9282 12.9273 12.181 12.3907 12.3859C12.6725 12.9525 12.9981 13.493 13.3662 14C14.8527 13.5351 16.3647 12.8246 17.9235 11.6536C18.2973 7.67707 17.285 4.22935 15.2477 1.17248ZM6.00988 9.54403C5.12079 9.54403 4.39167 8.71004 4.39167 7.69451C4.39167 6.67893 5.10521 5.84353 6.00988 5.84353C6.91456 5.84353 7.64365 6.67747 7.62808 7.69451C7.62954 8.71004 6.91456 9.54403 6.00988 9.54403ZM11.9901 9.54403C11.101 9.54403 10.3718 8.71004 10.3718 7.69451C10.3718 6.67893 11.0854 5.84353 11.9901 5.84353C12.8947 5.84353 13.6238 6.67747 13.6083 7.69451C13.6083 8.71004 12.8947 9.54403 11.9901 9.54403Z" fill="currentColor"></path></svg></a><a href="https://www.linkedin.com/company/exa-ai/" target="_blank" rel="noopener noreferrer" class="text-white" aria-label="Follow us on LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" width="17" viewBox="0 0 20 20" fill="none"><path d="M13.3333 6.66602C14.6593 6.66602 15.9311 7.1928 16.8688 8.13048C17.8065 9.06816 18.3333 10.3399 18.3333 11.666V17.4993H14.9999V11.666C14.9999 11.224 14.8243 10.8001 14.5118 10.4875C14.1992 10.1749 13.7753 9.99935 13.3333 9.99935C12.8912 9.99935 12.4673 10.1749 12.1547 10.4875C11.8422 10.8001 11.6666 11.224 11.6666 11.666V17.4993H8.33325V11.666C8.33325 10.3399 8.86004 9.06816 9.79772 8.13048C10.7354 7.1928 12.0072 6.66602 13.3333 6.66602Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M5.00008 7.5H1.66675V17.5H5.00008V7.5Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3.33341 4.99935C4.25389 4.99935 5.00008 4.25316 5.00008 3.33268C5.00008 2.41221 4.25389 1.66602 3.33341 1.66602C2.41294 1.66602 1.66675 2.41221 1.66675 3.33268C1.66675 4.25316 2.41294 4.99935 3.33341 4.99935Z" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></a><a href="https://github.com/exa-labs" target="_blank" rel="noopener noreferrer" class="text-white" aria-label="Follow us on GitHub"><svg width="16" height="16" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M12 0C5.37 0 0 5.37 0 12C0 17.31 3.435 21.795 8.205 23.385C8.805 23.49 9.03 23.13 9.03 22.815C9.03 22.53 9.015 21.585 9.015 20.58C6 21.135 5.22 19.845 4.98 19.17C4.845 18.825 4.26 17.76 3.75 17.475C3.33 17.25 2.73 16.695 3.735 16.68C4.68 16.665 5.355 17.55 5.58 17.91C6.66 19.725 8.385 19.215 9.075 18.9C9.18 18.12 9.495 17.595 9.84 17.295C7.17 16.995 4.38 15.96 4.38 11.37C4.38 10.065 4.845 8.985 5.61 8.145C5.49 7.845 5.07 6.615 5.73 4.965C5.73 4.965 6.735 4.65 9.03 6.195C9.99 5.925 11.01 5.79 12.03 5.79C13.05 5.79 14.07 5.925 15.03 6.195C17.325 4.635 18.33 4.965 18.33 4.965C18.99 6.615 18.57 7.845 18.45 8.145C19.215 8.985 19.68 10.05 19.68 11.37C19.68 15.975 16.875 16.995 14.205 17.295C14.64 17.67 15.015 18.39 15.015 19.515C15.015 21.12 15 22.41 15 22.815C15 23.13 15.225 23.505 15.825 23.385C18.2072 22.5807 20.2772 21.0497 21.7437 19.0074C23.2101 16.965 23.9993 14.5143 24 12C24 5.37 18.63 0 12 0Z" fill="currentColor"></path></svg></a></div><p class="text-xs opacity-50 text-white">© Copyright 2025 Exa — based in San Francisco</p><div class="flex items-center gap-4"><a href="/privacy-policy" class="text-xs opacity-50 text-white no-underline hover:cursor-pointer">Privacy Policy</a><a href="/assets/Exa_Labs_Terms_of_Service.pdf" target="_blank" rel="noopener noreferrer" class="text-xs opacity-50 text-white no-underline hover:cursor-pointer">Terms of Service</a></div></div></div></footer><script src="https://cdn.tolt.io/tolt.js" async="true" data-tolt="pk_Zaf65kQFEMtUeofUeGdum5pK" data-nscript="afterInteractive"></script><script src="https://www.googletagmanager.com/gtag/js?id=G-CPMTFL65Z3" data-nscript="afterInteractive"></script><script id="google-analytics-4" data-nscript="afterInteractive">
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-CPMTFL65Z3');
          </script><script src="https://www.googletagmanager.com/gtag/js?id=AW-16696812396" data-nscript="afterInteractive"></script><script id="google-analytics" data-nscript="afterInteractive">
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments);}
              gtag('js', new Date());
              gtag('config', 'AW-16696812396');
            </script><script id="google-conversion" data-nscript="afterInteractive">
              function gtag_report_conversion(url) {
                var callback = function () {
                  if (typeof(url) != 'undefined') {
                    window.location = url;
                  }
                };
                gtag('event', 'conversion', {
                    'send_to': 'AW-16696812396/RIf1CKmettUZEOzG1Jk-',
                    'event_callback': callback
                });
                return false;
              }
            </script><script id="reb2b-script" data-nscript="afterInteractive">
            !function () {
              var reb2b = window.reb2b = window.reb2b || [];
              if (reb2b.invoked) return;reb2b.invoked = true;
              reb2b.methods = ["identify", "collect"];
              reb2b.factory = function (method) {
                return function () {
                  var args = Array.prototype.slice.call(arguments);
                  args.unshift(method);
                  reb2b.push(args);
                  return reb2b;
                };
              };
              for (var i = 0; i < reb2b.methods.length; i++) {
                var key = reb2b.methods[i];
                reb2b[key] = reb2b.factory(key);
              }
              reb2b.load = function (key) {
                var script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.src = "https://s3-us-west-2.amazonaws.com/b2bjsstore/b/" + key + "/W6Z57HQ7J8OX.js.gz";
                var first = document.getElementsByTagName("script")[0];
                first.parentNode.insertBefore(script, first);
              };
              reb2b.SNIPPET_VERSION = "1.0.1";
              reb2b.load("W6Z57HQ7J8OX");
            }();
          </script><next-route-announcer style="position: absolute;"></next-route-announcer></body></html>